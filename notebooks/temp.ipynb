{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mental-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules for data manipulation\n",
    "from dotenv import load_dotenv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import call\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "employed-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules for machine learning\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Calculate the accurancy of the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# For drawing the graph\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "greek-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the list of products for each family\n",
    "# Les familles sont: CREDITS, DEPOTS MONETAIRES, PRODUITS EXTERNES COMMERCIALISES\n",
    "credit = ['00568', '00943', '00942', '00546', '00547', '03992', '00940', '00941', '00548', '06458', '00509', '00565']\n",
    "depot = ['07648', '07649', '07606', '00003']\n",
    "comm = ['05808', '05807']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hearing-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance,names,model_type):\n",
    "    #Create arrays from feature importance and feature name logistic regressions\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(10,8))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title(model_type + '-FEATURE IMPORTANCE')\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')\n",
    "    \n",
    "    plt.savefig('{}.svg'.format(model_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "mobile-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(data, ecos, cols):   \n",
    "    ''' The Model'''\n",
    "    \n",
    "    # Labels are the values we want to predict\n",
    "    labels = np.array(data['ECO'])\n",
    "\n",
    "    # Remove the labels from the features\n",
    "    features = np.array(data[cols])\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2)\n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf = RandomForestRegressor(n_estimators = 300)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf.fit(train_features, train_labels)\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = rf.predict(test_features)\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(test_labels, predictions.round()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "special-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(data, ecos, cols):\n",
    "    ''' The Model'''\n",
    "    \n",
    "    # Labels are the values we want to predict\n",
    "    labels = np.array(data['ECO'])\n",
    "\n",
    "    # Remove the labels from the features\n",
    "    features = np.array(data[cols])\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    logisticRegr = LogisticRegression()\n",
    "    \n",
    "    # Train the model on training data\n",
    "    logisticRegr.fit(train_features, train_labels)\n",
    "    \n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = logisticRegr.predict(test_features)\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(test_labels, predictions.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gross-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(data, ecos, cols):\n",
    "    ''' The Model'''\n",
    "\n",
    "    # Labels are the values we want to predict\n",
    "    labels = np.array(data['ECO'])\n",
    "\n",
    "    # Remove the labels from the features\n",
    "    features = np.array(data[cols])\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    # Train the model on training data\n",
    "    model.fit(train_features, train_labels)\n",
    "    \n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = model.predict(test_features)\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(test_labels, predictions.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "revolutionary-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from the other notebook\n",
    "%store -r data\n",
    "%store -r cols\n",
    "%store -r eco\n",
    "%store -r ctr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-romance",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "digital-norwegian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.86      0.84     69151\n",
      "        True       0.65      0.58      0.61     32128\n",
      "\n",
      "    accuracy                           0.77    101279\n",
      "   macro avg       0.73      0.72      0.72    101279\n",
      "weighted avg       0.76      0.77      0.77    101279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(data, eco, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "reflected-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' The Model'''\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(data['ECO'])\n",
    "\n",
    "# Remove the labels from the features\n",
    "features = np.array(data[cols])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "behavioral-berlin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2692.503211736679\n",
      "13.138068914413452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.91      0.90     69304\n",
      "        True       0.79      0.74      0.76     31975\n",
      "\n",
      "    accuracy                           0.86    101279\n",
      "   macro avg       0.84      0.82      0.83    101279\n",
      "weighted avg       0.85      0.86      0.85    101279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model with 300 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 300)\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)\n",
    "\n",
    "fn = time.time()\n",
    "print(fn - st)\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "print(time.time() - fn)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(test_labels, predictions.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "falling-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "shit = sorted(zip(cols, rf.feature_importances_), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "french-library",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGMIM\n",
      "CEBPF5\n",
      "MTEEML\n",
      "QTAGCL\n",
      "MTECSL\n",
      "LON\n",
      "LAT\n",
      "MTRSMO\n",
      "MCTOTA\n",
      "MTELEP\n"
     ]
    }
   ],
   "source": [
    "for i in shit[:10]:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-basement",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "approved-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-pantyhose",
   "metadata": {},
   "source": [
    "# CREDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "broken-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the ECO, to generate the new one\n",
    "temp = temp.drop(columns=['ECO'])\n",
    "\n",
    "# get the ids of the products\n",
    "ids = ctr[ctr['COPRO'].isin(credit)]['COMAX'].values\n",
    "temp['ECO'] = temp['COMAX'].isin(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "signal-configuration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      0.99    100130\n",
      "        True       0.60      0.09      0.16      1149\n",
      "\n",
      "    accuracy                           0.99    101279\n",
      "   macro avg       0.80      0.54      0.58    101279\n",
      "weighted avg       0.99      0.99      0.98    101279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(temp, credit, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "considerable-differential",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      0.99    100078\n",
      "        True       0.37      0.07      0.11      1201\n",
      "\n",
      "    accuracy                           0.99    101279\n",
      "   macro avg       0.68      0.53      0.55    101279\n",
      "weighted avg       0.98      0.99      0.98    101279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(temp, credit, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-northeast",
   "metadata": {},
   "source": [
    "# DEPOTS MONETAIRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "every-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the ECO, to generate the new one\n",
    "temp = temp.drop(columns=['ECO'])\n",
    "\n",
    "# get the ids of the products\n",
    "ids = ctr[ctr['COPRO'].isin(depot)]['COMAX'].values\n",
    "temp['ECO'] = temp['COMAX'].isin(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "french-standard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.92      0.90     69772\n",
      "        True       0.80      0.74      0.77     31507\n",
      "\n",
      "    accuracy                           0.86    101279\n",
      "   macro avg       0.84      0.83      0.83    101279\n",
      "weighted avg       0.86      0.86      0.86    101279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(temp, depot, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "grand-purple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.86      0.84     69686\n",
      "        True       0.65      0.57      0.61     31593\n",
      "\n",
      "    accuracy                           0.77    101279\n",
      "   macro avg       0.73      0.72      0.72    101279\n",
      "weighted avg       0.76      0.77      0.77    101279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(temp, depot, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-coaching",
   "metadata": {},
   "source": [
    "# Test The theory of Audrey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "defined-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp[temp['QTAGCL'] >= 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "going-sheep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.88      0.86     49683\n",
      "        True       0.79      0.75      0.77     31961\n",
      "\n",
      "    accuracy                           0.82     81644\n",
      "   macro avg       0.82      0.81      0.81     81644\n",
      "weighted avg       0.82      0.82      0.82     81644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(temp, eco, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-nebraska",
   "metadata": {},
   "source": [
    "# &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "contained-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' The Model'''\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(data['ECO'])\n",
    "\n",
    "# Remove the labels from the features\n",
    "features = np.array(data[['SGMIM', 'CEBPF5', 'MTEEML', 'QTAGCL', 'MTECSL', 'LON', 'LAT', 'MTRSMO', 'MCTOTA', 'MTELEP']])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "official-helicopter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714.0915184020996\n",
      "10.427082300186157\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.90      0.89     69387\n",
      "        True       0.77      0.73      0.75     31892\n",
      "\n",
      "    accuracy                           0.85    101279\n",
      "   macro avg       0.82      0.81      0.82    101279\n",
      "weighted avg       0.84      0.85      0.84    101279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model with 300 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 300)\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)\n",
    "\n",
    "fn = time.time()\n",
    "print(fn - st)\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "print(time.time() - fn)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(test_labels, predictions.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-coral",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
