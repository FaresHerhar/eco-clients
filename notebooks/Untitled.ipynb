{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hundred-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules for data manipulation\n",
    "from dotenv import load_dotenv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import call\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pressed-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules for machine learning\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Calculate the accurancy of the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# For drawing the graph\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alike-preference",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "impressed-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clt = pd.read_csv(os.getenv('CLEANED_DATA_PATH') + '/' + 'TJ38.csv', encoding='ISO-8859-1', sep='\\t')\n",
    "clt = pd.read_csv(os.getenv('CLEANED_DATA_PATH') + '/' + 'TR35.csv', encoding='ISO-8859-1', sep='\\t', low_memory=False)\n",
    "ctr = pd.read_csv(os.getenv('CLEANED_DATA_PATH') + '/' + 'TJ7S.csv', encoding='ISO-8859-1', sep='\\t', usecols=['COCO', 'COMAX', 'COPRO'], low_memory=False)\n",
    "\n",
    "eco = pd.read_csv(os.getenv('CLEANED_DATA_PATH') + '/' + 'eco-products.csv', encoding='ISO-8859-1', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-arabic",
   "metadata": {},
   "source": [
    "## Get the best ecological product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "transparent-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all the eco products code\n",
    "eco = [str(i).zfill(5) for i in eco['COPRO']]\n",
    "\n",
    "# Declare the list of products for each family\n",
    "# Les familles sont: CREDITS, DEPOTS MONETAIRES, PRODUITS EXTERNES COMMERCIALISES\n",
    "credit = ['568', '943', '942', '546', '547', '3992', '940', '941', '548', '6458', '509', '565']\n",
    "depot = ['7648', '7649', '7606', '3']\n",
    "comm = ['5808', '5807']\n",
    "\n",
    "# ECO: 00003 | 242568 - LIVRET DEVELOPPEMENT DURABLE ET SOLIDAIRE\n",
    "# DEPOTS MONETAIRES - EPARGNE MONETAIRE LIQUIDE - LIVRETS REGLEMENTES\n",
    "# ctr[ctr['COPRO'].isin(eco)]['COPRO'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-boating",
   "metadata": {},
   "source": [
    "## Concatinate with other tables TJ39 - TJDR - TJER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "entitled-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "tj39 = pd.read_csv(os.getenv('DATA_PATH') + '/' + 'tj39.csv', encoding='ISO-8859-1', sep=';', usecols=['COMAX', 'MSMENC', 'MTPATR', 'MTVAOP'])\n",
    "tjdr = pd.read_csv(os.getenv('DATA_PATH') + '/' + 'tjdr.csv', encoding='ISO-8859-1', sep=';', usecols=['COMAX', 'MTRVIM', 'MTRVFR', 'QTPAFI', 'COHAVI'])\n",
    "tjer = pd.read_csv(os.getenv('DATA_PATH') + '/' + 'tjer.csv', encoding='ISO-8859-1', sep=';', usecols=['COMAX', 'MTAPJE', 'MTPJE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "common-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour le cas de la table tj39, la variable COMAX elle est de 13 caracteres\n",
    "# or celle des autres tables sont de 10, donc il fallait convertir de 13 a 10\n",
    "# on prend les 10 premiers caractères du COMAX de tj39, d'apres le data engineer\n",
    "# de la PBS.\n",
    "tj39['COMAX'] = [val[:10] for val in tj39['COMAX'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "global-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This table is only good fot the moral clients only\n",
    "data = pd.merge(clt,tj39,on='COMAX',how='left')\n",
    "data = pd.merge(data,tjer,on='COMAX',how='left')\n",
    "data = pd.merge(data,tjdr,on='COMAX',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "finite-garlic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1689052, 120)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "center-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset=\"COMAX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "worst-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CTSCPI'] = data['CTSCPI'].astype(str)\n",
    "data['COPOST'] = data['COPOST'].astype(str)\n",
    "\n",
    "data['COPOST'].replace('nan', np.nan, inplace=True)\n",
    "data['CTSCPI'].replace('nan', np.nan, inplace=True)\n",
    "\n",
    "data.dropna(subset=['COPOST'], inplace=True)\n",
    "data.dropna(subset=['CTSCPI'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "loose-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace Male with 0, et F avec 1\n",
    "data['COSEXE'].replace('M', 0, inplace=True)\n",
    "data['COSEXE'].replace('F', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "completed-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ids of the products\n",
    "ids = ctr[ctr['COPRO'].isin(eco)]['COMAX'].values\n",
    "data['ECO'] = data['COMAX'].isin(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "diverse-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these values are based int but detected as object\n",
    "why = ['CTCOPO', 'CTMENB', 'CTSIFA', 'COPOAG', 'CTSC90', 'CTSC91', 'CTSC92', 'CTFORT','PSGPAR',\n",
    "'CEBPF1', 'CEBPF2', 'CEBPF3', 'CEBPF4', 'CEBPF5', 'CEBPF6', 'CEBPF7', 'CTBP']\n",
    "\n",
    "for i in why:\n",
    "    for k in [j for j in data[i].unique() if j.strip() == '']:\n",
    "         data[i].replace(k, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "nuclear-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_del = {'COHAVI', 'CERCPT', 'CERCPE', 'CERCEP', 'CERCPS', 'CERCPL', 'CERCPC', 'CERCPP', 'QCBPFA', 'COPOST', 'COGRRB', 'COESPF', 'QCLDD', 'MTELDD', 'COPOAG', 'QCCONT', 'QCLIVR', 'QCLIVJ', 'QCCSL', 'QCLEP', 'MTELDD', 'MTELIJ'}\n",
    "cols = list(data.columns.values[1:-1])\n",
    "\n",
    "for i in list(to_del):\n",
    "    cols.remove(i)\n",
    "\n",
    "for l in cols:\n",
    "    try:\n",
    "        data[l] = data[l].fillna(data[l].median())\n",
    "    except:\n",
    "        cols.remove(l)\n",
    "\n",
    "for l in cols:\n",
    "    if data[l].isna().sum() != 0:\n",
    "        data[l] = data[l].fillna(data[l].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "absolute-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cols:\n",
    "    if data[i].isna().sum() != 0:\n",
    "        print(i)\n",
    "# data['CTMENB'] = data[''].fillna(data[''].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "reserved-associate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "binary-chorus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'data' (DataFrame)\n",
      "Stored 'cols' (list)\n",
      "Stored 'eco' (list)\n"
     ]
    }
   ],
   "source": [
    "%store data\n",
    "%store cols\n",
    "%store eco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "forward-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(data, ecos, cols):   \n",
    "    ''' The Model'''\n",
    "    \n",
    "    # Labels are the values we want to predict\n",
    "    labels = np.array(data['ECO'])\n",
    "\n",
    "    # Remove the labels from the features\n",
    "    features = np.array(data[cols])\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2)\n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf = RandomForestRegressor(n_estimators = 300)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf.fit(train_features, train_labels)\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = rf.predict(test_features)\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(test_labels, predictions.round()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "organic-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(data, ecos, cols):\n",
    "    ''' The Model'''\n",
    "    \n",
    "    # Labels are the values we want to predict\n",
    "    labels = np.array(data['ECO'])\n",
    "\n",
    "    # Remove the labels from the features\n",
    "    features = np.array(data[cols])\n",
    "\n",
    "    # Split the data into training and testing sets, random_state = 42\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    model = KNeighborsClassifier(n_neighbors=3)\n",
    "    \n",
    "    # Train the model on training data\n",
    "    model.fit(train_features, train_labels)\n",
    "    \n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = model.predict(test_features)\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(test_labels, predictions.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "proper-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(data, ecos, cols):\n",
    "    ''' The Model'''\n",
    "    \n",
    "    # Labels are the values we want to predict\n",
    "    labels = np.array(data['ECO'])\n",
    "\n",
    "    # Remove the labels from the features\n",
    "    features = np.array(data[cols])\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    logisticRegr = LogisticRegression()\n",
    "    \n",
    "    # Train the model on training data\n",
    "    logisticRegr.fit(train_features, train_labels)\n",
    "    \n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = logisticRegr.predict(test_features)\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(test_labels, predictions.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "electrical-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' The Model'''\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(data['ECO'])\n",
    "\n",
    "# Remove the labels from the features\n",
    "features = np.array(data[cols])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "adverse-brave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2347.960119009018\n",
      "11.459137678146362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.91      0.90     69134\n",
      "        True       0.79      0.74      0.76     32145\n",
      "\n",
      "    accuracy                           0.86    101279\n",
      "   macro avg       0.84      0.82      0.83    101279\n",
      "weighted avg       0.85      0.86      0.85    101279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model with 300 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 300)\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)\n",
    "\n",
    "fn = time.time()\n",
    "print(fn - st)\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "print(time.time() - fn)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(test_labels, predictions.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "conscious-substitute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREDITS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.91      0.90     69279\n",
      "        True       0.79      0.74      0.77     32000\n",
      "\n",
      "    accuracy                           0.86    101279\n",
      "   macro avg       0.84      0.83      0.83    101279\n",
      "weighted avg       0.85      0.86      0.86    101279\n",
      "\n",
      "DEPOTS MONETAIRES\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.91      0.90     69200\n",
      "        True       0.79      0.74      0.77     32079\n",
      "\n",
      "    accuracy                           0.86    101279\n",
      "   macro avg       0.84      0.83      0.83    101279\n",
      "weighted avg       0.85      0.86      0.86    101279\n",
      "\n",
      "PRODUITS EXTERNES COMMERCIALISES\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.91      0.90     69007\n",
      "        True       0.79      0.74      0.77     32272\n",
      "\n",
      "    accuracy                           0.86    101279\n",
      "   macro avg       0.84      0.82      0.83    101279\n",
      "weighted avg       0.85      0.86      0.85    101279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CREDITS\n",
    "print('CREDITS')\n",
    "random_forest(data, credit, cols)\n",
    "\n",
    "# DEPOTS MONETAIRES\n",
    "print('DEPOTS MONETAIRES')\n",
    "random_forest(data, depot, cols)\n",
    "\n",
    "# PRODUITS EXTERNES COMMERCIALISES\n",
    "print('PRODUITS EXTERNES COMMERCIALISES')\n",
    "random_forest(data, comm, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-region",
   "metadata": {},
   "source": [
    "# Importance Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "charming-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance,names,model_type):\n",
    "    #Create arrays from feature importance and feature name logistic regressions\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(10,8))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title(model_type + '-FEATURE IMPORTANCE')\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')\n",
    "    \n",
    "    plt.savefig('{}.svg'.format(model_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(rf.feature_importances_[:30],cols[:30],'Random-Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lol in sorted(zip(cols, rf.feature_importances_), key=lambda x: x[1], reverse=True):\n",
    "    print(lol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-conspiracy",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fuzzy-spread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506392, 121)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "increased-arnold",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    346365\n",
      "True     160027\n",
      "Name: ECO, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['ECO'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "stuffed-messenger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    258539\n",
      "0    247853\n",
      "Name: COSEXE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['COSEXE'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "smaller-bulgarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-17 :: 98172\n",
      "18-39 :: 135327\n",
      "40-64 :: 173403\n",
      "65-~ :: 99490\n"
     ]
    }
   ],
   "source": [
    "print('0-17 ::', data[(0 <= data['QTAGCL']) & (data['QTAGCL'] < 18)]['COSEXE'].count())\n",
    "print('18-39 ::', data[(18 <= data['QTAGCL']) & (data['QTAGCL'] < 40)]['COSEXE'].count())\n",
    "print('40-64 ::', data[(40 <= data['QTAGCL']) & (data['QTAGCL'] < 65)]['COSEXE'].count())\n",
    "print('65-~ ::', data[65 <= data['QTAGCL']]['COSEXE'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "settled-spending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECO    COSEXE\n",
      "False  1         174093\n",
      "       0         172272\n",
      "True   1          84446\n",
      "       0          75581\n",
      "Name: COSEXE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# lol = ['COSEXE', 'QTAGCL', 'CTSCPI']\n",
    "print(data.groupby('ECO')['COSEXE'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "united-league",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-17 ::\n",
      " ECO\n",
      "False    97505\n",
      "True       667\n",
      "Name: COSEXE, dtype: int64 \n",
      "\n",
      "18-39 ::\n",
      " ECO\n",
      "False    100192\n",
      "True      35135\n",
      "Name: COSEXE, dtype: int64 \n",
      "\n",
      "40-64 ::\n",
      " ECO\n",
      "False    98117\n",
      "True     75286\n",
      "Name: COSEXE, dtype: int64 \n",
      "\n",
      "65-~ ::\n",
      " ECO\n",
      "False    50551\n",
      "True     48939\n",
      "Name: COSEXE, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('0-17 ::\\n', data[(0 <= data['QTAGCL']) & (data['QTAGCL'] < 18)].groupby('ECO')['COSEXE'].count(), '\\n')\n",
    "print('18-39 ::\\n', data[(18 <= data['QTAGCL']) & (data['QTAGCL'] < 40)].groupby('ECO')['COSEXE'].count(), '\\n')\n",
    "print('40-64 ::\\n', data[(40 <= data['QTAGCL']) & (data['QTAGCL'] < 65)].groupby('ECO')['COSEXE'].count(), '\\n')\n",
    "print('65-~ ::\\n', data[65 <= data['QTAGCL']].groupby('ECO')['COSEXE'].count(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "certified-surgery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMAX</th>\n",
       "      <th>CTCOPO</th>\n",
       "      <th>COESPF</th>\n",
       "      <th>COGRRB</th>\n",
       "      <th>COSGPA</th>\n",
       "      <th>CTMENB</th>\n",
       "      <th>COCINS</th>\n",
       "      <th>COPOST</th>\n",
       "      <th>CTSIFA</th>\n",
       "      <th>CTSCPI</th>\n",
       "      <th>...</th>\n",
       "      <th>MSMENC</th>\n",
       "      <th>MTPATR</th>\n",
       "      <th>MTVAOP</th>\n",
       "      <th>MTAPJE</th>\n",
       "      <th>MTPJE</th>\n",
       "      <th>COHAVI</th>\n",
       "      <th>MTRVIM</th>\n",
       "      <th>MTRVFR</th>\n",
       "      <th>QTPAFI</th>\n",
       "      <th>ECO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39e4b5c00a</td>\n",
       "      <td>582</td>\n",
       "      <td>d10869c66b</td>\n",
       "      <td>194acf0904</td>\n",
       "      <td>3200</td>\n",
       "      <td>04</td>\n",
       "      <td>34172</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77cedb77d9</td>\n",
       "      <td>527</td>\n",
       "      <td>c3ea678087</td>\n",
       "      <td>fd7c332a52</td>\n",
       "      <td>3200</td>\n",
       "      <td>07</td>\n",
       "      <td>66136</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cfb9f1d41b</td>\n",
       "      <td>542</td>\n",
       "      <td>76b274b0ad</td>\n",
       "      <td>e9a0dda18b</td>\n",
       "      <td>3200</td>\n",
       "      <td>07</td>\n",
       "      <td>66021</td>\n",
       "      <td>66430.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3a738f58cc</td>\n",
       "      <td>542</td>\n",
       "      <td>cb74f7d1d3</td>\n",
       "      <td>7044fd434c</td>\n",
       "      <td>3200</td>\n",
       "      <td>07</td>\n",
       "      <td>66148</td>\n",
       "      <td>66660.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>57fdb1b811</td>\n",
       "      <td>582</td>\n",
       "      <td>7db43147e8</td>\n",
       "      <td>85bda13ea9</td>\n",
       "      <td>3200</td>\n",
       "      <td>01</td>\n",
       "      <td>66050</td>\n",
       "      <td>66530.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         COMAX CTCOPO      COESPF      COGRRB COSGPA CTMENB COCINS   COPOST  \\\n",
       "0   39e4b5c00a    582  d10869c66b  194acf0904   3200     04  34172  34000.0   \n",
       "1   77cedb77d9    527  c3ea678087  fd7c332a52   3200     07  66136  66000.0   \n",
       "2   cfb9f1d41b    542  76b274b0ad  e9a0dda18b   3200     07  66021  66430.0   \n",
       "3   3a738f58cc    542  cb74f7d1d3  7044fd434c   3200     07  66148  66660.0   \n",
       "15  57fdb1b811    582  7db43147e8  85bda13ea9   3200     01  66050  66530.0   \n",
       "\n",
       "   CTSIFA  CTSCPI  ... MSMENC    MTPATR  MTVAOP  MTAPJE   MTPJE COHAVI  \\\n",
       "0       1  5500.0  ...    0.0  150000.0   150.0     0.0  4000.0    1.0   \n",
       "1       2  6700.0  ...    0.0  150000.0   150.0     0.0  4000.0    1.0   \n",
       "2       5  4700.0  ...    0.0  150000.0   150.0     0.0  4000.0    1.0   \n",
       "3       5  4200.0  ...    0.0  300000.0   300.0     0.0  4000.0    1.0   \n",
       "15      1  4300.0  ...    0.0  150000.0   150.0     0.0  4000.0    1.0   \n",
       "\n",
       "    MTRVIM  MTRVFR  QTPAFI    ECO  \n",
       "0      0.0   100.0     1.0  False  \n",
       "1      0.0   100.0     1.0  False  \n",
       "2      0.0   100.0     1.0   True  \n",
       "3      0.0   100.0     1.0   True  \n",
       "15     0.0   100.0     1.0  False  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-tucson",
   "metadata": {},
   "source": [
    "## Save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "catholic-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "ninja = ctr[ctr['COPRO'].isin(eco)][['COMAX', 'COPRO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "divine-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "ninja = ninja[ninja['COMAX'].isin(data[data['ECO'] == True]['COMAX'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "disciplinary-concrete",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215419, 2)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ninja.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "exact-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "ninja = list(zip(ninja['COPRO'].value_counts().index, ninja['COPRO'].value_counts().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "atomic-participant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPOT:: 00003 , 201998\n",
      "CREDIT:: 00546 , 4115\n",
      "CREDIT:: 00548 , 3598\n",
      "DEPOT:: 07649 , 2321\n",
      "CREDIT:: 00940 , 1734\n",
      "CREDIT:: 00547 , 832\n",
      "CREDIT:: 00509 , 379\n",
      "CREDIT:: 00941 , 299\n",
      "CREDIT:: 03992 , 85\n",
      "CREDIT:: 06458 , 52\n",
      "CREDIT:: 00565 , 6\n"
     ]
    }
   ],
   "source": [
    "for ko in ninja:\n",
    "    if ko[0] in credit:\n",
    "        print('CREDIT::', ko[0], ',', ko[1])\n",
    "    if ko[0] in depot:\n",
    "        print('DEPOT::', ko[0], ',', ko[1])\n",
    "    if ko[0] in comm:\n",
    "        print('COMM::', ko[0], ',', ko[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-dancing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
